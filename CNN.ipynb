{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing of general libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "\n",
    "# Image libraries\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Importing tsorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    'Dataset/Hiragana/model1',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "val_dataset = train_datagen.flow_from_directory(\n",
    "    'Dataset/Hiragana/model1',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprop = fm.FontProperties(fname='NotoSansJP-Bold.ttf')\n",
    "print(\"hello\", matplotlib.matplotlib_fname())\n",
    "\n",
    "# Set the path to the parent folder containing the subfolders with images\n",
    "parent_folder = \"Images/alpha\"\n",
    "\n",
    "# Create a list to store the number of images in each subfolder\n",
    "image_counts = []\n",
    "\n",
    "# Loop through each subfolder\n",
    "for folder_name in os.listdir(parent_folder):\n",
    "    folder_path = os.path.join(parent_folder, folder_name)\n",
    "    \n",
    "    # Check if the subfolder is actually a folder (not a file)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Count the number of files in the subfolder and append to image_counts list\n",
    "        count = len(os.listdir(folder_path))\n",
    "        image_counts.append(count)\n",
    "\n",
    "\n",
    "# Create the countplot with subfolder names as labels\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Number of Images in Each Hiragana Character Subfolder\")\n",
    "plt.xlabel(\"Subfolder Names\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.xticks(rotation=0, fontproperties=fprop ,fontsize=12)\n",
    "plt.bar(os.listdir(parent_folder), image_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=40)\n",
    "\n",
    "# Evaluate the model\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_dataset = test_datagen.flow_from_directory(\n",
    "    'Hiragan_test',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,9))\n",
    "pred = model.predict(test_dataset)\n",
    "y_pred = np.argmax(pred, axis=1)\n",
    "y_true = np.argmax(test_dataset, axis=1)\n",
    "cm = confusion_matrix(y_true,y_pred)\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', xticklabels = class_names, yticklabels = class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('Test_imagees/Hiragana_letter_A.png')\n",
    "\n",
    "# Morphological filtering\n",
    "from skimage.morphology import opening\n",
    "from skimage.morphology import disk\n",
    "# Connected component filtering\n",
    "import cv2\n",
    "# Data handling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Convert image to RGB mode\n",
    "img = img.convert('RGB')\n",
    "img = img.resize((32, 32))\n",
    "\n",
    "black = 0\n",
    "white = 255\n",
    "threshold = 250\n",
    "\n",
    "# Load the image\n",
    "pixels = np.array(img)[:,:,0]\n",
    "\n",
    "# Apply the thresholding\n",
    "pixels[pixels > threshold] = white\n",
    "pixels[pixels < threshold] = black\n",
    "\n",
    "# Morphological opening\n",
    "blobSize = 1 # Select the maximum radius of the blobs you would like to remove\n",
    "structureElement = disk(blobSize)  # you can define different shapes, here we take a disk shape\n",
    "# We need to invert the image such that black is background and white foreground to perform the opening\n",
    "pixels = np.invert(opening(np.invert(pixels), structureElement))\n",
    "\n",
    "newImg = Image.fromarray(pixels).convert('RGB')\n",
    "nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(np.invert(pixels), connectivity=8)\n",
    "\n",
    "plt.imshow(newImg)\n",
    "plt.show()\n",
    "img_array = np.array(newImg)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = test_datagen.flow(img_array).next()\n",
    "\n",
    "import os\n",
    "\n",
    "# Get the class names\n",
    "class_names = sorted(os.listdir('Hiragan_test'))\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "prediction = model.predict(img_array)\n",
    "predicted_label = class_names[np.argmax(prediction)]\n",
    "\n",
    "print(\"Predicted label:\", predicted_label)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
